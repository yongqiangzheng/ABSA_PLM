cuda memory allocated: 499894784
> n_trainable_params: 124647939, n_nontrainable_params: 0
> training arguments:
>>> model_name: roberta
>>> dataset: mams
>>> optimizer: adam
>>> repeat: 3
>>> lr: 2e-05
>>> l2reg: 0.0001
>>> num_epoch: 100
>>> batch_size: 16
>>> log_step: 10
>>> bert_dim: 768
>>> max_seq_len: 128
>>> polarities_dim: 3
>>> patience: 5
>>> device: cuda
>>> seed: 42
>>> save_model_dir: /media/b115/Backup/NLP
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
loss: 1.0984, acc: 0.3875
loss: 1.0959, acc: 0.3781
loss: 1.0809, acc: 0.4250
loss: 1.0647, acc: 0.4453
loss: 1.0543, acc: 0.4425
loss: 1.0458, acc: 0.4479
loss: 1.0372, acc: 0.4562
loss: 1.0282, acc: 0.4695
loss: 1.0162, acc: 0.4813
loss: 0.9980, acc: 0.4938
loss: 0.9833, acc: 0.5080
loss: 0.9675, acc: 0.5219
loss: 0.9476, acc: 0.5337
loss: 0.9353, acc: 0.5393
loss: 0.9225, acc: 0.5479
loss: 0.9103, acc: 0.5578
loss: 0.8987, acc: 0.5680
loss: 0.8842, acc: 0.5788
loss: 0.8661, acc: 0.5885
loss: 0.8607, acc: 0.5928
loss: 0.8499, acc: 0.6006
loss: 0.8454, acc: 0.6051
loss: 0.8377, acc: 0.6095
loss: 0.8291, acc: 0.6148
loss: 0.8203, acc: 0.6198
loss: 0.8119, acc: 0.6243
loss: 0.8074, acc: 0.6266
loss: 0.7987, acc: 0.6321
loss: 0.7890, acc: 0.6377
loss: 0.7810, acc: 0.6412
loss: 0.7766, acc: 0.6448
loss: 0.7747, acc: 0.6467
loss: 0.7697, acc: 0.6502
loss: 0.7598, acc: 0.6548
loss: 0.7524, acc: 0.6589
loss: 0.7471, acc: 0.6615
loss: 0.7428, acc: 0.6639
loss: 0.7358, acc: 0.6674
loss: 0.7336, acc: 0.6678
loss: 0.7296, acc: 0.6709
loss: 0.7258, acc: 0.6735
loss: 0.7187, acc: 0.6775
loss: 0.7163, acc: 0.6789
loss: 0.7121, acc: 0.6813
loss: 0.7112, acc: 0.6829
loss: 0.7073, acc: 0.6853
loss: 0.7028, acc: 0.6883
loss: 0.6987, acc: 0.6909
loss: 0.6966, acc: 0.6920
loss: 0.6934, acc: 0.6941
loss: 0.6889, acc: 0.6968
loss: 0.6839, acc: 0.7000
loss: 0.6826, acc: 0.7012
loss: 0.6787, acc: 0.7030
loss: 0.6742, acc: 0.7053
loss: 0.6704, acc: 0.7079
loss: 0.6657, acc: 0.7107
loss: 0.6616, acc: 0.7125
loss: 0.6578, acc: 0.7144
loss: 0.6557, acc: 0.7158
loss: 0.6530, acc: 0.7173
loss: 0.6507, acc: 0.7183
loss: 0.6469, acc: 0.7210
loss: 0.6444, acc: 0.7226
loss: 0.6417, acc: 0.7238
loss: 0.6396, acc: 0.7246
loss: 0.6376, acc: 0.7258
loss: 0.6364, acc: 0.7267
loss: 0.6337, acc: 0.7279
loss: 0.6318, acc: 0.7287
> val_acc: 0.7965, val_f1: 0.7875
>> saved: /media/b115/Backup/NLP/roberta/mams/acc_0.7965_f1_0.7875_230828-0652.model
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.4079, acc: 0.8625
loss: 0.3700, acc: 0.8719
loss: 0.3695, acc: 0.8667
loss: 0.3811, acc: 0.8688
loss: 0.3756, acc: 0.8675
loss: 0.4012, acc: 0.8625
loss: 0.4051, acc: 0.8589
loss: 0.4078, acc: 0.8562
loss: 0.4025, acc: 0.8562
loss: 0.4030, acc: 0.8544
loss: 0.4188, acc: 0.8489
loss: 0.4110, acc: 0.8495
loss: 0.4084, acc: 0.8514
loss: 0.4097, acc: 0.8482
loss: 0.4099, acc: 0.8475
loss: 0.4027, acc: 0.8512
loss: 0.4011, acc: 0.8507
loss: 0.3978, acc: 0.8517
loss: 0.3977, acc: 0.8510
loss: 0.3991, acc: 0.8509
loss: 0.3998, acc: 0.8503
loss: 0.4007, acc: 0.8511
loss: 0.4002, acc: 0.8516
loss: 0.3992, acc: 0.8523
loss: 0.3948, acc: 0.8535
loss: 0.3944, acc: 0.8543
loss: 0.3929, acc: 0.8537
loss: 0.3914, acc: 0.8545
loss: 0.3912, acc: 0.8545
loss: 0.3896, acc: 0.8550
loss: 0.3892, acc: 0.8544
loss: 0.3922, acc: 0.8537
loss: 0.3931, acc: 0.8538
loss: 0.3922, acc: 0.8531
loss: 0.3931, acc: 0.8534
loss: 0.3936, acc: 0.8519
loss: 0.3928, acc: 0.8524
loss: 0.3913, acc: 0.8526
loss: 0.3924, acc: 0.8519
loss: 0.3906, acc: 0.8527
loss: 0.3915, acc: 0.8515
loss: 0.3905, acc: 0.8518
loss: 0.3904, acc: 0.8519
loss: 0.3874, acc: 0.8531
loss: 0.3865, acc: 0.8531
loss: 0.3852, acc: 0.8538
loss: 0.3848, acc: 0.8533
loss: 0.3863, acc: 0.8533
loss: 0.3869, acc: 0.8531
loss: 0.3861, acc: 0.8534
loss: 0.3861, acc: 0.8533
loss: 0.3862, acc: 0.8531
loss: 0.3856, acc: 0.8537
loss: 0.3844, acc: 0.8544
loss: 0.3849, acc: 0.8545
loss: 0.3877, acc: 0.8539
loss: 0.3868, acc: 0.8543
loss: 0.3873, acc: 0.8537
loss: 0.3881, acc: 0.8534
loss: 0.3882, acc: 0.8532
loss: 0.3891, acc: 0.8530
loss: 0.3903, acc: 0.8525
loss: 0.3906, acc: 0.8522
loss: 0.3904, acc: 0.8522
loss: 0.3899, acc: 0.8526
loss: 0.3898, acc: 0.8522
loss: 0.3885, acc: 0.8533
loss: 0.3890, acc: 0.8531
loss: 0.3885, acc: 0.8536
loss: 0.3878, acc: 0.8537
> val_acc: 0.8348, val_f1: 0.8293
>> saved: /media/b115/Backup/NLP/roberta/mams/acc_0.8348_f1_0.8293_230828-0654.model
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.2353, acc: 0.9250
loss: 0.2504, acc: 0.9156
loss: 0.2559, acc: 0.9146
loss: 0.2649, acc: 0.9094
loss: 0.2535, acc: 0.9163
loss: 0.2561, acc: 0.9156
loss: 0.2511, acc: 0.9187
loss: 0.2526, acc: 0.9172
loss: 0.2569, acc: 0.9139
loss: 0.2552, acc: 0.9131
loss: 0.2593, acc: 0.9119
loss: 0.2547, acc: 0.9130
loss: 0.2563, acc: 0.9115
loss: 0.2575, acc: 0.9121
loss: 0.2588, acc: 0.9096
loss: 0.2579, acc: 0.9090
loss: 0.2557, acc: 0.9096
loss: 0.2551, acc: 0.9090
loss: 0.2598, acc: 0.9076
loss: 0.2594, acc: 0.9075
loss: 0.2590, acc: 0.9080
loss: 0.2634, acc: 0.9057
loss: 0.2625, acc: 0.9068
loss: 0.2615, acc: 0.9070
loss: 0.2647, acc: 0.9052
loss: 0.2627, acc: 0.9065
loss: 0.2651, acc: 0.9056
loss: 0.2668, acc: 0.9042
loss: 0.2668, acc: 0.9039
loss: 0.2653, acc: 0.9050
loss: 0.2646, acc: 0.9054
loss: 0.2662, acc: 0.9049
loss: 0.2652, acc: 0.9057
loss: 0.2641, acc: 0.9061
loss: 0.2670, acc: 0.9054
loss: 0.2684, acc: 0.9045
loss: 0.2661, acc: 0.9054
loss: 0.2637, acc: 0.9059
loss: 0.2689, acc: 0.9051
loss: 0.2707, acc: 0.9048
loss: 0.2701, acc: 0.9049
loss: 0.2700, acc: 0.9049
loss: 0.2704, acc: 0.9049
loss: 0.2705, acc: 0.9047
loss: 0.2708, acc: 0.9050
loss: 0.2702, acc: 0.9052
loss: 0.2696, acc: 0.9059
loss: 0.2704, acc: 0.9056
loss: 0.2699, acc: 0.9057
loss: 0.2694, acc: 0.9056
loss: 0.2697, acc: 0.9059
loss: 0.2709, acc: 0.9050
loss: 0.2715, acc: 0.9047
loss: 0.2700, acc: 0.9052
loss: 0.2714, acc: 0.9049
loss: 0.2712, acc: 0.9051
loss: 0.2707, acc: 0.9054
loss: 0.2707, acc: 0.9055
loss: 0.2722, acc: 0.9047
loss: 0.2717, acc: 0.9048
loss: 0.2718, acc: 0.9049
loss: 0.2705, acc: 0.9055
loss: 0.2710, acc: 0.9056
loss: 0.2735, acc: 0.9046
loss: 0.2742, acc: 0.9042
loss: 0.2741, acc: 0.9042
loss: 0.2752, acc: 0.9036
loss: 0.2740, acc: 0.9042
loss: 0.2741, acc: 0.9038
loss: 0.2733, acc: 0.9035
> val_acc: 0.8446, val_f1: 0.8385
>> saved: /media/b115/Backup/NLP/roberta/mams/acc_0.8446_f1_0.8385_230828-0656.model
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 0.1382, acc: 0.9375
loss: 0.1330, acc: 0.9469
loss: 0.1563, acc: 0.9333
loss: 0.1560, acc: 0.9391
loss: 0.1613, acc: 0.9375
loss: 0.1608, acc: 0.9385
loss: 0.1596, acc: 0.9402
loss: 0.1527, acc: 0.9437
loss: 0.1679, acc: 0.9396
loss: 0.1648, acc: 0.9413
loss: 0.1710, acc: 0.9403
loss: 0.1755, acc: 0.9380
loss: 0.1784, acc: 0.9370
loss: 0.1763, acc: 0.9379
loss: 0.1837, acc: 0.9354
loss: 0.1824, acc: 0.9348
loss: 0.1849, acc: 0.9342
loss: 0.1818, acc: 0.9361
loss: 0.1811, acc: 0.9355
loss: 0.1840, acc: 0.9341
loss: 0.1817, acc: 0.9354
loss: 0.1795, acc: 0.9366
loss: 0.1811, acc: 0.9361
loss: 0.1825, acc: 0.9362
loss: 0.1853, acc: 0.9350
loss: 0.1850, acc: 0.9358
loss: 0.1870, acc: 0.9359
loss: 0.1847, acc: 0.9364
loss: 0.1850, acc: 0.9364
loss: 0.1852, acc: 0.9365
loss: 0.1839, acc: 0.9367
loss: 0.1808, acc: 0.9381
loss: 0.1802, acc: 0.9386
loss: 0.1790, acc: 0.9392
loss: 0.1777, acc: 0.9396
loss: 0.1779, acc: 0.9398
loss: 0.1768, acc: 0.9400
loss: 0.1782, acc: 0.9391
loss: 0.1790, acc: 0.9391
loss: 0.1785, acc: 0.9392
loss: 0.1796, acc: 0.9387
loss: 0.1786, acc: 0.9390
loss: 0.1775, acc: 0.9397
loss: 0.1792, acc: 0.9395
loss: 0.1797, acc: 0.9396
loss: 0.1792, acc: 0.9397
loss: 0.1790, acc: 0.9394
loss: 0.1786, acc: 0.9391
loss: 0.1795, acc: 0.9386
loss: 0.1817, acc: 0.9376
loss: 0.1830, acc: 0.9373
loss: 0.1840, acc: 0.9367
loss: 0.1839, acc: 0.9369
loss: 0.1840, acc: 0.9369
loss: 0.1855, acc: 0.9365
loss: 0.1861, acc: 0.9362
loss: 0.1848, acc: 0.9367
loss: 0.1842, acc: 0.9371
loss: 0.1836, acc: 0.9373
loss: 0.1840, acc: 0.9375
loss: 0.1838, acc: 0.9373
loss: 0.1856, acc: 0.9369
loss: 0.1866, acc: 0.9363
loss: 0.1868, acc: 0.9358
loss: 0.1871, acc: 0.9359
loss: 0.1870, acc: 0.9357
loss: 0.1868, acc: 0.9358
loss: 0.1863, acc: 0.9361
loss: 0.1870, acc: 0.9361
loss: 0.1881, acc: 0.9357
> val_acc: 0.8288, val_f1: 0.8256
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
loss: 0.1800, acc: 0.9313
loss: 0.2018, acc: 0.9219
loss: 0.1708, acc: 0.9354
loss: 0.1512, acc: 0.9437
loss: 0.1455, acc: 0.9463
loss: 0.1483, acc: 0.9458
loss: 0.1393, acc: 0.9491
loss: 0.1360, acc: 0.9492
loss: 0.1398, acc: 0.9479
loss: 0.1350, acc: 0.9500
loss: 0.1357, acc: 0.9511
loss: 0.1354, acc: 0.9516
loss: 0.1334, acc: 0.9524
loss: 0.1345, acc: 0.9527
loss: 0.1308, acc: 0.9533
loss: 0.1313, acc: 0.9527
loss: 0.1338, acc: 0.9526
loss: 0.1346, acc: 0.9521
loss: 0.1323, acc: 0.9530
loss: 0.1328, acc: 0.9525
loss: 0.1318, acc: 0.9530
loss: 0.1319, acc: 0.9528
loss: 0.1344, acc: 0.9524
loss: 0.1317, acc: 0.9539
loss: 0.1298, acc: 0.9543
loss: 0.1298, acc: 0.9550
loss: 0.1315, acc: 0.9542
loss: 0.1365, acc: 0.9525
loss: 0.1358, acc: 0.9530
loss: 0.1358, acc: 0.9531
loss: 0.1354, acc: 0.9534
loss: 0.1346, acc: 0.9541
loss: 0.1357, acc: 0.9542
loss: 0.1351, acc: 0.9539
loss: 0.1343, acc: 0.9541
loss: 0.1347, acc: 0.9536
loss: 0.1339, acc: 0.9537
loss: 0.1333, acc: 0.9538
loss: 0.1349, acc: 0.9535
loss: 0.1343, acc: 0.9541
loss: 0.1330, acc: 0.9544
loss: 0.1328, acc: 0.9546
loss: 0.1324, acc: 0.9547
loss: 0.1321, acc: 0.9550
loss: 0.1302, acc: 0.9557
loss: 0.1303, acc: 0.9557
loss: 0.1320, acc: 0.9551
loss: 0.1327, acc: 0.9552
loss: 0.1314, acc: 0.9555
loss: 0.1308, acc: 0.9554
loss: 0.1305, acc: 0.9556
loss: 0.1300, acc: 0.9554
loss: 0.1292, acc: 0.9558
loss: 0.1280, acc: 0.9559
loss: 0.1268, acc: 0.9563
loss: 0.1267, acc: 0.9565
loss: 0.1295, acc: 0.9556
loss: 0.1313, acc: 0.9545
loss: 0.1326, acc: 0.9541
loss: 0.1333, acc: 0.9539
loss: 0.1331, acc: 0.9537
loss: 0.1342, acc: 0.9534
loss: 0.1342, acc: 0.9533
loss: 0.1345, acc: 0.9531
loss: 0.1343, acc: 0.9530
loss: 0.1354, acc: 0.9527
loss: 0.1359, acc: 0.9526
loss: 0.1370, acc: 0.9522
loss: 0.1371, acc: 0.9523
loss: 0.1369, acc: 0.9523
> val_acc: 0.8386, val_f1: 0.8315
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 5
loss: 0.1161, acc: 0.9375
loss: 0.0755, acc: 0.9656
loss: 0.0620, acc: 0.9729
loss: 0.0730, acc: 0.9703
loss: 0.0875, acc: 0.9688
loss: 0.0774, acc: 0.9719
loss: 0.0785, acc: 0.9732
loss: 0.0773, acc: 0.9742
loss: 0.0849, acc: 0.9729
loss: 0.0858, acc: 0.9738
loss: 0.0851, acc: 0.9744
loss: 0.0881, acc: 0.9724
loss: 0.0850, acc: 0.9736
loss: 0.0869, acc: 0.9714
loss: 0.0866, acc: 0.9721
loss: 0.0854, acc: 0.9723
loss: 0.0858, acc: 0.9721
loss: 0.0848, acc: 0.9729
loss: 0.0861, acc: 0.9727
loss: 0.0888, acc: 0.9716
loss: 0.0917, acc: 0.9702
loss: 0.0926, acc: 0.9696
loss: 0.0908, acc: 0.9704
loss: 0.0919, acc: 0.9695
loss: 0.0896, acc: 0.9705
loss: 0.0892, acc: 0.9707
loss: 0.0894, acc: 0.9708
loss: 0.0901, acc: 0.9699
loss: 0.0919, acc: 0.9694
loss: 0.0938, acc: 0.9688
loss: 0.0945, acc: 0.9681
loss: 0.0941, acc: 0.9682
loss: 0.0944, acc: 0.9682
loss: 0.0936, acc: 0.9684
loss: 0.0926, acc: 0.9686
loss: 0.0933, acc: 0.9682
loss: 0.0923, acc: 0.9684
loss: 0.0920, acc: 0.9686
loss: 0.0915, acc: 0.9688
loss: 0.0920, acc: 0.9689
loss: 0.0926, acc: 0.9688
loss: 0.0950, acc: 0.9677
loss: 0.0962, acc: 0.9674
loss: 0.0962, acc: 0.9673
loss: 0.0960, acc: 0.9672
loss: 0.0954, acc: 0.9673
loss: 0.0972, acc: 0.9665
loss: 0.0979, acc: 0.9661
loss: 0.0973, acc: 0.9663
loss: 0.0977, acc: 0.9659
loss: 0.0986, acc: 0.9657
loss: 0.0991, acc: 0.9654
loss: 0.0983, acc: 0.9656
loss: 0.0978, acc: 0.9659
loss: 0.0971, acc: 0.9660
loss: 0.0977, acc: 0.9658
loss: 0.0984, acc: 0.9657
loss: 0.0981, acc: 0.9658
loss: 0.0988, acc: 0.9656
loss: 0.0988, acc: 0.9657
loss: 0.0984, acc: 0.9659
loss: 0.0991, acc: 0.9654
loss: 0.0984, acc: 0.9658
loss: 0.0984, acc: 0.9657
loss: 0.0985, acc: 0.9659
loss: 0.0983, acc: 0.9658
loss: 0.0989, acc: 0.9659
loss: 0.0996, acc: 0.9655
loss: 0.0997, acc: 0.9655
loss: 0.0995, acc: 0.9654
> val_acc: 0.8281, val_f1: 0.8247
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 6
loss: 0.0893, acc: 0.9750
loss: 0.0633, acc: 0.9781
loss: 0.0485, acc: 0.9854
loss: 0.0587, acc: 0.9828
loss: 0.0533, acc: 0.9850
loss: 0.0621, acc: 0.9823
loss: 0.0568, acc: 0.9839
loss: 0.0526, acc: 0.9852
loss: 0.0495, acc: 0.9861
loss: 0.0488, acc: 0.9856
loss: 0.0480, acc: 0.9847
loss: 0.0484, acc: 0.9854
loss: 0.0473, acc: 0.9856
loss: 0.0507, acc: 0.9848
loss: 0.0525, acc: 0.9838
loss: 0.0520, acc: 0.9840
loss: 0.0539, acc: 0.9824
loss: 0.0521, acc: 0.9833
loss: 0.0522, acc: 0.9832
loss: 0.0545, acc: 0.9825
loss: 0.0558, acc: 0.9824
loss: 0.0572, acc: 0.9818
loss: 0.0566, acc: 0.9818
loss: 0.0575, acc: 0.9815
loss: 0.0609, acc: 0.9810
loss: 0.0618, acc: 0.9808
loss: 0.0627, acc: 0.9801
loss: 0.0637, acc: 0.9795
loss: 0.0651, acc: 0.9782
loss: 0.0656, acc: 0.9775
loss: 0.0659, acc: 0.9774
loss: 0.0663, acc: 0.9773
loss: 0.0660, acc: 0.9773
loss: 0.0670, acc: 0.9772
loss: 0.0684, acc: 0.9768
loss: 0.0689, acc: 0.9762
loss: 0.0698, acc: 0.9758
loss: 0.0709, acc: 0.9757
loss: 0.0728, acc: 0.9753
loss: 0.0743, acc: 0.9745
loss: 0.0756, acc: 0.9741
loss: 0.0783, acc: 0.9737
loss: 0.0775, acc: 0.9741
loss: 0.0781, acc: 0.9734
loss: 0.0784, acc: 0.9731
loss: 0.0786, acc: 0.9731
loss: 0.0781, acc: 0.9734
loss: 0.0787, acc: 0.9732
loss: 0.0778, acc: 0.9735
loss: 0.0779, acc: 0.9735
loss: 0.0789, acc: 0.9727
loss: 0.0787, acc: 0.9727
loss: 0.0782, acc: 0.9728
loss: 0.0786, acc: 0.9728
loss: 0.0801, acc: 0.9725
loss: 0.0815, acc: 0.9721
loss: 0.0822, acc: 0.9720
loss: 0.0829, acc: 0.9719
loss: 0.0831, acc: 0.9718
loss: 0.0825, acc: 0.9721
loss: 0.0827, acc: 0.9720
loss: 0.0836, acc: 0.9715
loss: 0.0846, acc: 0.9712
loss: 0.0843, acc: 0.9710
loss: 0.0839, acc: 0.9711
loss: 0.0840, acc: 0.9711
loss: 0.0840, acc: 0.9712
loss: 0.0842, acc: 0.9711
loss: 0.0837, acc: 0.9713
loss: 0.0828, acc: 0.9717
> val_acc: 0.8401, val_f1: 0.8344
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 7
loss: 0.0257, acc: 0.9938
loss: 0.0316, acc: 0.9875
loss: 0.0360, acc: 0.9833
loss: 0.0349, acc: 0.9844
loss: 0.0497, acc: 0.9838
loss: 0.0566, acc: 0.9833
loss: 0.0558, acc: 0.9821
loss: 0.0529, acc: 0.9836
loss: 0.0524, acc: 0.9826
loss: 0.0551, acc: 0.9806
loss: 0.0549, acc: 0.9807
loss: 0.0515, acc: 0.9823
loss: 0.0521, acc: 0.9822
loss: 0.0511, acc: 0.9826
loss: 0.0521, acc: 0.9821
loss: 0.0533, acc: 0.9812
loss: 0.0539, acc: 0.9805
loss: 0.0540, acc: 0.9806
loss: 0.0572, acc: 0.9796
loss: 0.0559, acc: 0.9806
loss: 0.0553, acc: 0.9810
loss: 0.0573, acc: 0.9801
loss: 0.0588, acc: 0.9796
loss: 0.0618, acc: 0.9792
loss: 0.0649, acc: 0.9790
loss: 0.0678, acc: 0.9776
loss: 0.0714, acc: 0.9764
loss: 0.0715, acc: 0.9768
loss: 0.0716, acc: 0.9765
loss: 0.0714, acc: 0.9767
loss: 0.0714, acc: 0.9764
loss: 0.0713, acc: 0.9764
loss: 0.0707, acc: 0.9765
loss: 0.0704, acc: 0.9761
loss: 0.0716, acc: 0.9761
loss: 0.0726, acc: 0.9752
loss: 0.0734, acc: 0.9747
loss: 0.0757, acc: 0.9745
loss: 0.0758, acc: 0.9744
loss: 0.0783, acc: 0.9738
loss: 0.0788, acc: 0.9735
loss: 0.0799, acc: 0.9735
loss: 0.0793, acc: 0.9735
loss: 0.0789, acc: 0.9739
loss: 0.0783, acc: 0.9742
loss: 0.0790, acc: 0.9738
loss: 0.0801, acc: 0.9733
loss: 0.0797, acc: 0.9733
loss: 0.0796, acc: 0.9735
loss: 0.0796, acc: 0.9736
loss: 0.0801, acc: 0.9733
loss: 0.0792, acc: 0.9737
loss: 0.0793, acc: 0.9733
loss: 0.0796, acc: 0.9730
loss: 0.0794, acc: 0.9731
loss: 0.0791, acc: 0.9732
loss: 0.0787, acc: 0.9735
loss: 0.0783, acc: 0.9735
loss: 0.0785, acc: 0.9736
loss: 0.0776, acc: 0.9739
loss: 0.0770, acc: 0.9739
loss: 0.0771, acc: 0.9739
loss: 0.0767, acc: 0.9741
loss: 0.0766, acc: 0.9740
loss: 0.0761, acc: 0.9742
loss: 0.0762, acc: 0.9741
loss: 0.0760, acc: 0.9740
loss: 0.0761, acc: 0.9739
loss: 0.0754, acc: 0.9741
loss: 0.0751, acc: 0.9743
> val_acc: 0.8341, val_f1: 0.8300
>> test_acc: 0.8331, test_f1: 0.8264
cuda memory allocated: 2541904384
> n_trainable_params: 124647939, n_nontrainable_params: 0
> training arguments:
>>> model_name: roberta
>>> dataset: mams
>>> optimizer: adam
>>> repeat: 3
>>> lr: 2e-05
>>> l2reg: 0.0001
>>> num_epoch: 100
>>> batch_size: 16
>>> log_step: 10
>>> bert_dim: 768
>>> max_seq_len: 128
>>> polarities_dim: 3
>>> patience: 5
>>> device: cuda
>>> seed: 42
>>> save_model_dir: /media/b115/Backup/NLP
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
loss: 1.0943, acc: 0.3563
loss: 1.0726, acc: 0.4188
loss: 1.0766, acc: 0.4250
loss: 1.0755, acc: 0.4234
loss: 1.0731, acc: 0.4338
loss: 1.0692, acc: 0.4365
loss: 1.0677, acc: 0.4321
loss: 1.0570, acc: 0.4367
loss: 1.0378, acc: 0.4472
loss: 1.0222, acc: 0.4644
loss: 1.0017, acc: 0.4818
loss: 0.9807, acc: 0.4974
loss: 0.9631, acc: 0.5106
loss: 0.9445, acc: 0.5254
loss: 0.9344, acc: 0.5337
loss: 0.9190, acc: 0.5449
loss: 0.8976, acc: 0.5585
loss: 0.8803, acc: 0.5708
loss: 0.8630, acc: 0.5813
loss: 0.8555, acc: 0.5887
loss: 0.8485, acc: 0.5949
loss: 0.8397, acc: 0.6017
loss: 0.8290, acc: 0.6076
loss: 0.8175, acc: 0.6148
loss: 0.8118, acc: 0.6200
loss: 0.8050, acc: 0.6240
loss: 0.7970, acc: 0.6294
loss: 0.7875, acc: 0.6350
loss: 0.7797, acc: 0.6399
loss: 0.7729, acc: 0.6435
loss: 0.7615, acc: 0.6506
loss: 0.7531, acc: 0.6555
loss: 0.7465, acc: 0.6593
loss: 0.7380, acc: 0.6642
loss: 0.7348, acc: 0.6666
loss: 0.7305, acc: 0.6694
loss: 0.7244, acc: 0.6725
loss: 0.7189, acc: 0.6765
loss: 0.7145, acc: 0.6795
loss: 0.7089, acc: 0.6823
loss: 0.7035, acc: 0.6860
loss: 0.6999, acc: 0.6872
loss: 0.6949, acc: 0.6903
loss: 0.6878, acc: 0.6937
loss: 0.6843, acc: 0.6960
loss: 0.6808, acc: 0.6973
loss: 0.6776, acc: 0.6999
loss: 0.6734, acc: 0.7020
loss: 0.6699, acc: 0.7046
loss: 0.6659, acc: 0.7069
loss: 0.6632, acc: 0.7081
loss: 0.6605, acc: 0.7105
loss: 0.6585, acc: 0.7120
loss: 0.6553, acc: 0.7132
loss: 0.6515, acc: 0.7157
loss: 0.6521, acc: 0.7160
loss: 0.6500, acc: 0.7173
loss: 0.6461, acc: 0.7193
loss: 0.6414, acc: 0.7219
loss: 0.6402, acc: 0.7231
loss: 0.6372, acc: 0.7252
loss: 0.6360, acc: 0.7262
loss: 0.6324, acc: 0.7283
loss: 0.6297, acc: 0.7294
loss: 0.6285, acc: 0.7302
loss: 0.6262, acc: 0.7315
loss: 0.6248, acc: 0.7327
loss: 0.6229, acc: 0.7337
loss: 0.6213, acc: 0.7341
loss: 0.6198, acc: 0.7350
> val_acc: 0.8183, val_f1: 0.8130
>> saved: /media/b115/Backup/NLP/roberta/mams/acc_0.8183_f1_0.813_230828-0709.model
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.3047, acc: 0.8938
loss: 0.3336, acc: 0.8781
loss: 0.3372, acc: 0.8771
loss: 0.3502, acc: 0.8766
loss: 0.3689, acc: 0.8638
loss: 0.3737, acc: 0.8646
loss: 0.3734, acc: 0.8634
loss: 0.3682, acc: 0.8656
loss: 0.3734, acc: 0.8646
loss: 0.3717, acc: 0.8612
loss: 0.3734, acc: 0.8619
loss: 0.3739, acc: 0.8609
loss: 0.3749, acc: 0.8582
loss: 0.3723, acc: 0.8589
loss: 0.3728, acc: 0.8600
loss: 0.3699, acc: 0.8621
loss: 0.3729, acc: 0.8607
loss: 0.3730, acc: 0.8622
loss: 0.3755, acc: 0.8615
loss: 0.3750, acc: 0.8622
loss: 0.3772, acc: 0.8619
loss: 0.3799, acc: 0.8608
loss: 0.3792, acc: 0.8595
loss: 0.3820, acc: 0.8589
loss: 0.3825, acc: 0.8578
loss: 0.3818, acc: 0.8584
loss: 0.3791, acc: 0.8600
loss: 0.3788, acc: 0.8598
loss: 0.3788, acc: 0.8597
loss: 0.3759, acc: 0.8612
loss: 0.3740, acc: 0.8615
loss: 0.3730, acc: 0.8615
loss: 0.3725, acc: 0.8614
loss: 0.3730, acc: 0.8608
loss: 0.3749, acc: 0.8609
loss: 0.3742, acc: 0.8609
loss: 0.3769, acc: 0.8596
loss: 0.3733, acc: 0.8610
loss: 0.3767, acc: 0.8599
loss: 0.3771, acc: 0.8606
loss: 0.3777, acc: 0.8604
loss: 0.3769, acc: 0.8606
loss: 0.3764, acc: 0.8605
loss: 0.3777, acc: 0.8597
loss: 0.3804, acc: 0.8578
loss: 0.3803, acc: 0.8575
loss: 0.3817, acc: 0.8569
loss: 0.3808, acc: 0.8570
loss: 0.3816, acc: 0.8565
loss: 0.3803, acc: 0.8571
loss: 0.3802, acc: 0.8574
loss: 0.3787, acc: 0.8584
loss: 0.3793, acc: 0.8584
loss: 0.3810, acc: 0.8573
loss: 0.3811, acc: 0.8575
loss: 0.3795, acc: 0.8583
loss: 0.3781, acc: 0.8591
loss: 0.3775, acc: 0.8594
loss: 0.3781, acc: 0.8590
loss: 0.3772, acc: 0.8593
loss: 0.3780, acc: 0.8592
loss: 0.3792, acc: 0.8588
loss: 0.3792, acc: 0.8590
loss: 0.3793, acc: 0.8587
loss: 0.3792, acc: 0.8586
loss: 0.3799, acc: 0.8586
loss: 0.3807, acc: 0.8585
loss: 0.3814, acc: 0.8582
loss: 0.3831, acc: 0.8570
loss: 0.3833, acc: 0.8571
> val_acc: 0.8228, val_f1: 0.8194
>> saved: /media/b115/Backup/NLP/roberta/mams/acc_0.8228_f1_0.8194_230828-0711.model
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.2148, acc: 0.9500
loss: 0.2419, acc: 0.9344
loss: 0.2549, acc: 0.9167
loss: 0.2407, acc: 0.9203
loss: 0.2269, acc: 0.9263
loss: 0.2310, acc: 0.9198
loss: 0.2279, acc: 0.9223
loss: 0.2329, acc: 0.9203
loss: 0.2227, acc: 0.9236
loss: 0.2386, acc: 0.9163
loss: 0.2443, acc: 0.9153
loss: 0.2543, acc: 0.9130
loss: 0.2483, acc: 0.9154
loss: 0.2561, acc: 0.9112
loss: 0.2570, acc: 0.9108
loss: 0.2511, acc: 0.9129
loss: 0.2540, acc: 0.9107
loss: 0.2558, acc: 0.9090
loss: 0.2563, acc: 0.9095
loss: 0.2571, acc: 0.9081
loss: 0.2592, acc: 0.9071
loss: 0.2635, acc: 0.9054
loss: 0.2662, acc: 0.9043
loss: 0.2678, acc: 0.9036
loss: 0.2650, acc: 0.9052
loss: 0.2668, acc: 0.9034
loss: 0.2651, acc: 0.9039
loss: 0.2666, acc: 0.9033
loss: 0.2667, acc: 0.9037
loss: 0.2665, acc: 0.9042
loss: 0.2688, acc: 0.9038
loss: 0.2664, acc: 0.9037
loss: 0.2673, acc: 0.9038
loss: 0.2693, acc: 0.9028
loss: 0.2700, acc: 0.9021
loss: 0.2692, acc: 0.9028
loss: 0.2681, acc: 0.9035
loss: 0.2714, acc: 0.9023
loss: 0.2717, acc: 0.9027
loss: 0.2710, acc: 0.9031
loss: 0.2687, acc: 0.9044
loss: 0.2704, acc: 0.9037
loss: 0.2694, acc: 0.9045
loss: 0.2694, acc: 0.9044
loss: 0.2705, acc: 0.9035
loss: 0.2697, acc: 0.9034
loss: 0.2705, acc: 0.9029
loss: 0.2708, acc: 0.9029
loss: 0.2704, acc: 0.9028
loss: 0.2677, acc: 0.9039
loss: 0.2689, acc: 0.9033
loss: 0.2680, acc: 0.9035
loss: 0.2681, acc: 0.9032
loss: 0.2697, acc: 0.9027
loss: 0.2697, acc: 0.9026
loss: 0.2702, acc: 0.9021
loss: 0.2706, acc: 0.9025
loss: 0.2720, acc: 0.9020
loss: 0.2720, acc: 0.9021
loss: 0.2719, acc: 0.9024
loss: 0.2707, acc: 0.9028
loss: 0.2710, acc: 0.9024
loss: 0.2703, acc: 0.9030
loss: 0.2702, acc: 0.9032
loss: 0.2703, acc: 0.9033
loss: 0.2698, acc: 0.9036
loss: 0.2710, acc: 0.9033
loss: 0.2706, acc: 0.9031
loss: 0.2711, acc: 0.9028
loss: 0.2708, acc: 0.9031
> val_acc: 0.8311, val_f1: 0.8246
>> saved: /media/b115/Backup/NLP/roberta/mams/acc_0.8311_f1_0.8246_230828-0713.model
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 0.1494, acc: 0.9500
loss: 0.1922, acc: 0.9313
loss: 0.1775, acc: 0.9375
loss: 0.1822, acc: 0.9359
loss: 0.1803, acc: 0.9363
loss: 0.1864, acc: 0.9323
loss: 0.1842, acc: 0.9295
loss: 0.1839, acc: 0.9305
loss: 0.1845, acc: 0.9319
loss: 0.1998, acc: 0.9275
loss: 0.2041, acc: 0.9244
loss: 0.1987, acc: 0.9255
loss: 0.2006, acc: 0.9255
loss: 0.1989, acc: 0.9272
loss: 0.1968, acc: 0.9271
loss: 0.1977, acc: 0.9266
loss: 0.1967, acc: 0.9276
loss: 0.1986, acc: 0.9274
loss: 0.1981, acc: 0.9283
loss: 0.1941, acc: 0.9294
loss: 0.1960, acc: 0.9295
loss: 0.1910, acc: 0.9310
loss: 0.1864, acc: 0.9329
loss: 0.1848, acc: 0.9323
loss: 0.1862, acc: 0.9327
loss: 0.1877, acc: 0.9327
loss: 0.1922, acc: 0.9301
loss: 0.1899, acc: 0.9310
loss: 0.1907, acc: 0.9315
loss: 0.1902, acc: 0.9319
loss: 0.1886, acc: 0.9329
loss: 0.1904, acc: 0.9330
loss: 0.1894, acc: 0.9335
loss: 0.1898, acc: 0.9331
loss: 0.1880, acc: 0.9337
loss: 0.1880, acc: 0.9342
loss: 0.1898, acc: 0.9340
loss: 0.1883, acc: 0.9342
loss: 0.1866, acc: 0.9345
loss: 0.1873, acc: 0.9336
loss: 0.1883, acc: 0.9328
loss: 0.1891, acc: 0.9329
loss: 0.1904, acc: 0.9328
loss: 0.1912, acc: 0.9324
loss: 0.1927, acc: 0.9315
loss: 0.1943, acc: 0.9306
loss: 0.1957, acc: 0.9301
loss: 0.1965, acc: 0.9298
loss: 0.1947, acc: 0.9306
loss: 0.1969, acc: 0.9301
loss: 0.1962, acc: 0.9304
loss: 0.1960, acc: 0.9304
loss: 0.1962, acc: 0.9302
loss: 0.1972, acc: 0.9301
loss: 0.1965, acc: 0.9303
loss: 0.1967, acc: 0.9304
loss: 0.1996, acc: 0.9296
loss: 0.1991, acc: 0.9296
loss: 0.1982, acc: 0.9299
loss: 0.1979, acc: 0.9299
loss: 0.1968, acc: 0.9302
loss: 0.1966, acc: 0.9305
loss: 0.1957, acc: 0.9308
loss: 0.1957, acc: 0.9307
loss: 0.1958, acc: 0.9308
loss: 0.1966, acc: 0.9303
loss: 0.1965, acc: 0.9306
loss: 0.1960, acc: 0.9308
loss: 0.1960, acc: 0.9308
loss: 0.1956, acc: 0.9312
> val_acc: 0.8183, val_f1: 0.8168
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
loss: 0.1309, acc: 0.9563
loss: 0.1133, acc: 0.9625
loss: 0.1165, acc: 0.9625
loss: 0.1112, acc: 0.9625
loss: 0.0985, acc: 0.9688
loss: 0.1083, acc: 0.9635
loss: 0.1144, acc: 0.9643
loss: 0.1179, acc: 0.9617
loss: 0.1164, acc: 0.9604
loss: 0.1197, acc: 0.9594
loss: 0.1178, acc: 0.9597
loss: 0.1192, acc: 0.9583
loss: 0.1147, acc: 0.9601
loss: 0.1109, acc: 0.9621
loss: 0.1065, acc: 0.9637
loss: 0.1076, acc: 0.9629
loss: 0.1070, acc: 0.9632
loss: 0.1098, acc: 0.9622
loss: 0.1125, acc: 0.9615
loss: 0.1150, acc: 0.9600
loss: 0.1185, acc: 0.9589
loss: 0.1217, acc: 0.9574
loss: 0.1235, acc: 0.9573
loss: 0.1253, acc: 0.9565
loss: 0.1273, acc: 0.9555
loss: 0.1263, acc: 0.9560
loss: 0.1256, acc: 0.9563
loss: 0.1283, acc: 0.9556
loss: 0.1278, acc: 0.9558
loss: 0.1312, acc: 0.9550
loss: 0.1327, acc: 0.9544
loss: 0.1353, acc: 0.9535
loss: 0.1353, acc: 0.9536
loss: 0.1362, acc: 0.9533
loss: 0.1379, acc: 0.9525
loss: 0.1368, acc: 0.9531
loss: 0.1385, acc: 0.9529
loss: 0.1385, acc: 0.9526
loss: 0.1378, acc: 0.9529
loss: 0.1397, acc: 0.9525
loss: 0.1412, acc: 0.9520
loss: 0.1406, acc: 0.9519
loss: 0.1394, acc: 0.9526
loss: 0.1387, acc: 0.9530
loss: 0.1377, acc: 0.9535
loss: 0.1366, acc: 0.9541
loss: 0.1374, acc: 0.9537
loss: 0.1391, acc: 0.9533
loss: 0.1392, acc: 0.9532
loss: 0.1382, acc: 0.9535
loss: 0.1377, acc: 0.9534
loss: 0.1383, acc: 0.9534
loss: 0.1388, acc: 0.9532
loss: 0.1383, acc: 0.9534
loss: 0.1384, acc: 0.9532
loss: 0.1388, acc: 0.9532
loss: 0.1392, acc: 0.9532
loss: 0.1391, acc: 0.9536
loss: 0.1390, acc: 0.9539
loss: 0.1391, acc: 0.9534
loss: 0.1382, acc: 0.9536
loss: 0.1381, acc: 0.9538
loss: 0.1377, acc: 0.9540
loss: 0.1375, acc: 0.9541
loss: 0.1381, acc: 0.9541
loss: 0.1379, acc: 0.9540
loss: 0.1373, acc: 0.9542
loss: 0.1378, acc: 0.9539
loss: 0.1382, acc: 0.9536
loss: 0.1371, acc: 0.9540
> val_acc: 0.8341, val_f1: 0.8275
>> saved: /media/b115/Backup/NLP/roberta/mams/acc_0.8341_f1_0.8275_230828-0718.model
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 5
loss: 0.0902, acc: 0.9625
loss: 0.0856, acc: 0.9688
loss: 0.0708, acc: 0.9771
loss: 0.0654, acc: 0.9781
loss: 0.0745, acc: 0.9775
loss: 0.0754, acc: 0.9781
loss: 0.0704, acc: 0.9804
loss: 0.0682, acc: 0.9805
loss: 0.0713, acc: 0.9778
loss: 0.0722, acc: 0.9775
loss: 0.0757, acc: 0.9750
loss: 0.0729, acc: 0.9755
loss: 0.0707, acc: 0.9769
loss: 0.0683, acc: 0.9777
loss: 0.0718, acc: 0.9767
loss: 0.0755, acc: 0.9766
loss: 0.0732, acc: 0.9772
loss: 0.0719, acc: 0.9778
loss: 0.0706, acc: 0.9776
loss: 0.0685, acc: 0.9788
loss: 0.0688, acc: 0.9789
loss: 0.0692, acc: 0.9790
loss: 0.0731, acc: 0.9774
loss: 0.0747, acc: 0.9776
loss: 0.0730, acc: 0.9782
loss: 0.0773, acc: 0.9764
loss: 0.0814, acc: 0.9757
loss: 0.0810, acc: 0.9761
loss: 0.0802, acc: 0.9759
loss: 0.0814, acc: 0.9754
loss: 0.0828, acc: 0.9748
loss: 0.0825, acc: 0.9752
loss: 0.0825, acc: 0.9756
loss: 0.0827, acc: 0.9756
loss: 0.0851, acc: 0.9752
loss: 0.0844, acc: 0.9753
loss: 0.0850, acc: 0.9753
loss: 0.0858, acc: 0.9752
loss: 0.0863, acc: 0.9748
loss: 0.0879, acc: 0.9741
loss: 0.0876, acc: 0.9741
loss: 0.0881, acc: 0.9738
loss: 0.0896, acc: 0.9734
loss: 0.0898, acc: 0.9736
loss: 0.0919, acc: 0.9729
loss: 0.0916, acc: 0.9731
loss: 0.0906, acc: 0.9733
loss: 0.0911, acc: 0.9727
loss: 0.0923, acc: 0.9721
loss: 0.0930, acc: 0.9715
loss: 0.0919, acc: 0.9719
loss: 0.0917, acc: 0.9719
loss: 0.0927, acc: 0.9713
loss: 0.0926, acc: 0.9712
loss: 0.0930, acc: 0.9709
loss: 0.0923, acc: 0.9712
loss: 0.0928, acc: 0.9711
loss: 0.0924, acc: 0.9711
loss: 0.0935, acc: 0.9708
loss: 0.0951, acc: 0.9701
loss: 0.0952, acc: 0.9700
loss: 0.0959, acc: 0.9696
loss: 0.0955, acc: 0.9697
loss: 0.0945, acc: 0.9701
loss: 0.0935, acc: 0.9705
loss: 0.0930, acc: 0.9707
loss: 0.0930, acc: 0.9707
loss: 0.0944, acc: 0.9702
loss: 0.0952, acc: 0.9698
loss: 0.0958, acc: 0.9699
> val_acc: 0.8176, val_f1: 0.8166
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 6
loss: 0.0576, acc: 0.9812
loss: 0.0564, acc: 0.9844
loss: 0.0762, acc: 0.9771
loss: 0.0784, acc: 0.9766
loss: 0.0696, acc: 0.9800
loss: 0.0699, acc: 0.9792
loss: 0.0657, acc: 0.9812
loss: 0.0639, acc: 0.9812
loss: 0.0637, acc: 0.9812
loss: 0.0639, acc: 0.9819
loss: 0.0593, acc: 0.9835
loss: 0.0585, acc: 0.9833
loss: 0.0616, acc: 0.9822
loss: 0.0632, acc: 0.9812
loss: 0.0667, acc: 0.9800
loss: 0.0646, acc: 0.9809
loss: 0.0649, acc: 0.9805
loss: 0.0638, acc: 0.9809
loss: 0.0683, acc: 0.9803
loss: 0.0690, acc: 0.9803
loss: 0.0680, acc: 0.9807
loss: 0.0687, acc: 0.9801
loss: 0.0733, acc: 0.9785
loss: 0.0727, acc: 0.9786
loss: 0.0748, acc: 0.9780
loss: 0.0750, acc: 0.9776
loss: 0.0741, acc: 0.9780
loss: 0.0754, acc: 0.9777
loss: 0.0744, acc: 0.9778
loss: 0.0753, acc: 0.9773
loss: 0.0750, acc: 0.9772
loss: 0.0740, acc: 0.9773
loss: 0.0749, acc: 0.9771
loss: 0.0751, acc: 0.9772
loss: 0.0747, acc: 0.9773
loss: 0.0747, acc: 0.9774
loss: 0.0756, acc: 0.9770
loss: 0.0750, acc: 0.9773
loss: 0.0748, acc: 0.9771
loss: 0.0750, acc: 0.9770
loss: 0.0746, acc: 0.9773
loss: 0.0753, acc: 0.9771
loss: 0.0758, acc: 0.9769
loss: 0.0758, acc: 0.9768
loss: 0.0752, acc: 0.9772
loss: 0.0745, acc: 0.9774
loss: 0.0754, acc: 0.9771
loss: 0.0762, acc: 0.9766
loss: 0.0759, acc: 0.9768
loss: 0.0754, acc: 0.9770
loss: 0.0753, acc: 0.9770
loss: 0.0762, acc: 0.9766
loss: 0.0779, acc: 0.9761
loss: 0.0784, acc: 0.9760
loss: 0.0806, acc: 0.9756
loss: 0.0803, acc: 0.9756
loss: 0.0808, acc: 0.9754
loss: 0.0810, acc: 0.9752
loss: 0.0817, acc: 0.9750
loss: 0.0814, acc: 0.9751
loss: 0.0816, acc: 0.9750
loss: 0.0825, acc: 0.9747
loss: 0.0825, acc: 0.9746
loss: 0.0827, acc: 0.9743
loss: 0.0828, acc: 0.9743
loss: 0.0827, acc: 0.9743
loss: 0.0831, acc: 0.9740
loss: 0.0834, acc: 0.9740
loss: 0.0835, acc: 0.9739
loss: 0.0842, acc: 0.9738
> val_acc: 0.8318, val_f1: 0.8273
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 7
loss: 0.0373, acc: 0.9812
loss: 0.0443, acc: 0.9812
loss: 0.0790, acc: 0.9729
loss: 0.0631, acc: 0.9797
loss: 0.0587, acc: 0.9812
loss: 0.0722, acc: 0.9760
loss: 0.0705, acc: 0.9777
loss: 0.0719, acc: 0.9766
loss: 0.0681, acc: 0.9785
loss: 0.0675, acc: 0.9781
loss: 0.0682, acc: 0.9778
loss: 0.0685, acc: 0.9781
loss: 0.0669, acc: 0.9788
loss: 0.0634, acc: 0.9804
loss: 0.0630, acc: 0.9804
loss: 0.0649, acc: 0.9789
loss: 0.0659, acc: 0.9787
loss: 0.0701, acc: 0.9774
loss: 0.0696, acc: 0.9773
loss: 0.0687, acc: 0.9775
loss: 0.0681, acc: 0.9777
loss: 0.0681, acc: 0.9776
loss: 0.0670, acc: 0.9780
loss: 0.0656, acc: 0.9784
loss: 0.0653, acc: 0.9788
loss: 0.0646, acc: 0.9788
loss: 0.0657, acc: 0.9787
loss: 0.0664, acc: 0.9786
loss: 0.0657, acc: 0.9787
loss: 0.0646, acc: 0.9790
loss: 0.0640, acc: 0.9790
loss: 0.0649, acc: 0.9787
loss: 0.0642, acc: 0.9790
loss: 0.0636, acc: 0.9792
loss: 0.0622, acc: 0.9796
loss: 0.0628, acc: 0.9795
loss: 0.0623, acc: 0.9799
loss: 0.0641, acc: 0.9796
loss: 0.0634, acc: 0.9800
loss: 0.0645, acc: 0.9794
loss: 0.0638, acc: 0.9796
loss: 0.0641, acc: 0.9798
loss: 0.0631, acc: 0.9801
loss: 0.0629, acc: 0.9801
loss: 0.0627, acc: 0.9800
loss: 0.0643, acc: 0.9795
loss: 0.0639, acc: 0.9795
loss: 0.0645, acc: 0.9792
loss: 0.0648, acc: 0.9788
loss: 0.0648, acc: 0.9786
loss: 0.0647, acc: 0.9784
loss: 0.0645, acc: 0.9785
loss: 0.0649, acc: 0.9782
loss: 0.0653, acc: 0.9780
loss: 0.0649, acc: 0.9781
loss: 0.0643, acc: 0.9781
loss: 0.0638, acc: 0.9784
loss: 0.0633, acc: 0.9787
loss: 0.0630, acc: 0.9787
loss: 0.0645, acc: 0.9784
loss: 0.0643, acc: 0.9786
loss: 0.0645, acc: 0.9786
loss: 0.0652, acc: 0.9783
loss: 0.0653, acc: 0.9781
loss: 0.0657, acc: 0.9779
loss: 0.0670, acc: 0.9777
loss: 0.0673, acc: 0.9778
loss: 0.0671, acc: 0.9779
loss: 0.0674, acc: 0.9779
loss: 0.0675, acc: 0.9779
> val_acc: 0.8303, val_f1: 0.8281
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 8
loss: 0.0190, acc: 0.9938
loss: 0.0421, acc: 0.9906
loss: 0.0550, acc: 0.9812
loss: 0.0527, acc: 0.9828
loss: 0.0579, acc: 0.9838
loss: 0.0625, acc: 0.9812
loss: 0.0572, acc: 0.9830
loss: 0.0528, acc: 0.9844
loss: 0.0515, acc: 0.9840
loss: 0.0489, acc: 0.9850
loss: 0.0450, acc: 0.9864
loss: 0.0475, acc: 0.9859
loss: 0.0526, acc: 0.9846
loss: 0.0552, acc: 0.9844
loss: 0.0534, acc: 0.9846
loss: 0.0548, acc: 0.9848
loss: 0.0530, acc: 0.9849
loss: 0.0526, acc: 0.9851
loss: 0.0552, acc: 0.9839
loss: 0.0567, acc: 0.9831
loss: 0.0584, acc: 0.9821
loss: 0.0583, acc: 0.9818
loss: 0.0569, acc: 0.9821
loss: 0.0555, acc: 0.9823
loss: 0.0547, acc: 0.9825
loss: 0.0533, acc: 0.9832
loss: 0.0528, acc: 0.9829
loss: 0.0561, acc: 0.9812
loss: 0.0566, acc: 0.9810
loss: 0.0564, acc: 0.9810
loss: 0.0557, acc: 0.9815
loss: 0.0556, acc: 0.9814
loss: 0.0551, acc: 0.9812
loss: 0.0564, acc: 0.9811
loss: 0.0570, acc: 0.9807
loss: 0.0581, acc: 0.9804
loss: 0.0583, acc: 0.9806
loss: 0.0576, acc: 0.9809
loss: 0.0585, acc: 0.9806
loss: 0.0584, acc: 0.9806
loss: 0.0595, acc: 0.9802
loss: 0.0587, acc: 0.9805
loss: 0.0579, acc: 0.9808
loss: 0.0579, acc: 0.9807
loss: 0.0575, acc: 0.9810
loss: 0.0574, acc: 0.9810
loss: 0.0569, acc: 0.9811
loss: 0.0561, acc: 0.9814
loss: 0.0554, acc: 0.9815
loss: 0.0549, acc: 0.9818
loss: 0.0554, acc: 0.9819
loss: 0.0567, acc: 0.9819
loss: 0.0582, acc: 0.9815
loss: 0.0581, acc: 0.9817
loss: 0.0598, acc: 0.9809
loss: 0.0600, acc: 0.9808
loss: 0.0597, acc: 0.9809
loss: 0.0595, acc: 0.9811
loss: 0.0588, acc: 0.9814
loss: 0.0594, acc: 0.9811
loss: 0.0595, acc: 0.9811
loss: 0.0603, acc: 0.9810
loss: 0.0599, acc: 0.9812
loss: 0.0599, acc: 0.9813
loss: 0.0595, acc: 0.9814
loss: 0.0592, acc: 0.9816
loss: 0.0588, acc: 0.9817
loss: 0.0588, acc: 0.9818
loss: 0.0586, acc: 0.9819
loss: 0.0581, acc: 0.9821
> val_acc: 0.8341, val_f1: 0.8276
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 9
loss: 0.0766, acc: 0.9625
loss: 0.0441, acc: 0.9812
loss: 0.0450, acc: 0.9854
loss: 0.0412, acc: 0.9859
loss: 0.0423, acc: 0.9862
loss: 0.0443, acc: 0.9854
loss: 0.0482, acc: 0.9848
loss: 0.0534, acc: 0.9844
loss: 0.0515, acc: 0.9840
loss: 0.0544, acc: 0.9838
loss: 0.0585, acc: 0.9824
loss: 0.0555, acc: 0.9839
loss: 0.0572, acc: 0.9832
loss: 0.0597, acc: 0.9821
loss: 0.0580, acc: 0.9825
loss: 0.0619, acc: 0.9816
loss: 0.0595, acc: 0.9820
loss: 0.0586, acc: 0.9819
loss: 0.0582, acc: 0.9816
loss: 0.0583, acc: 0.9812
loss: 0.0584, acc: 0.9815
loss: 0.0563, acc: 0.9824
loss: 0.0545, acc: 0.9829
loss: 0.0533, acc: 0.9833
loss: 0.0527, acc: 0.9835
loss: 0.0512, acc: 0.9839
loss: 0.0512, acc: 0.9836
loss: 0.0504, acc: 0.9839
loss: 0.0503, acc: 0.9841
loss: 0.0513, acc: 0.9835
loss: 0.0517, acc: 0.9835
loss: 0.0503, acc: 0.9840
loss: 0.0514, acc: 0.9839
loss: 0.0509, acc: 0.9838
loss: 0.0526, acc: 0.9834
loss: 0.0524, acc: 0.9832
loss: 0.0516, acc: 0.9834
loss: 0.0510, acc: 0.9837
loss: 0.0517, acc: 0.9833
loss: 0.0512, acc: 0.9833
loss: 0.0513, acc: 0.9835
loss: 0.0511, acc: 0.9835
loss: 0.0527, acc: 0.9833
loss: 0.0545, acc: 0.9827
loss: 0.0536, acc: 0.9831
loss: 0.0537, acc: 0.9830
loss: 0.0538, acc: 0.9828
loss: 0.0529, acc: 0.9832
loss: 0.0528, acc: 0.9833
loss: 0.0532, acc: 0.9831
loss: 0.0523, acc: 0.9835
loss: 0.0529, acc: 0.9833
loss: 0.0527, acc: 0.9834
loss: 0.0532, acc: 0.9832
loss: 0.0535, acc: 0.9832
loss: 0.0538, acc: 0.9830
loss: 0.0540, acc: 0.9829
loss: 0.0538, acc: 0.9828
loss: 0.0538, acc: 0.9827
loss: 0.0541, acc: 0.9827
loss: 0.0544, acc: 0.9827
loss: 0.0550, acc: 0.9823
loss: 0.0551, acc: 0.9819
loss: 0.0562, acc: 0.9816
loss: 0.0571, acc: 0.9814
loss: 0.0568, acc: 0.9815
loss: 0.0566, acc: 0.9815
loss: 0.0572, acc: 0.9813
loss: 0.0573, acc: 0.9813
loss: 0.0572, acc: 0.9814
> val_acc: 0.8326, val_f1: 0.8276
>> test_acc: 0.8211, test_f1: 0.8130
cuda memory allocated: 2547147264
> n_trainable_params: 124647939, n_nontrainable_params: 0
> training arguments:
>>> model_name: roberta
>>> dataset: mams
>>> optimizer: adam
>>> repeat: 3
>>> lr: 2e-05
>>> l2reg: 0.0001
>>> num_epoch: 100
>>> batch_size: 16
>>> log_step: 10
>>> bert_dim: 768
>>> max_seq_len: 128
>>> polarities_dim: 3
>>> patience: 5
>>> device: cuda
>>> seed: 42
>>> save_model_dir: /media/b115/Backup/NLP
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
loss: 1.0852, acc: 0.4313
loss: 1.0954, acc: 0.4281
loss: 1.0873, acc: 0.4458
loss: 1.0814, acc: 0.4500
loss: 1.0761, acc: 0.4475
loss: 1.0673, acc: 0.4583
loss: 1.0550, acc: 0.4562
loss: 1.0455, acc: 0.4562
loss: 1.0356, acc: 0.4583
loss: 1.0295, acc: 0.4631
loss: 1.0228, acc: 0.4682
loss: 1.0173, acc: 0.4703
loss: 1.0082, acc: 0.4716
loss: 1.0023, acc: 0.4777
loss: 0.9960, acc: 0.4800
loss: 0.9871, acc: 0.4867
loss: 0.9835, acc: 0.4908
loss: 0.9717, acc: 0.4997
loss: 0.9624, acc: 0.5069
loss: 0.9501, acc: 0.5153
loss: 0.9366, acc: 0.5241
loss: 0.9249, acc: 0.5330
loss: 0.9137, acc: 0.5405
loss: 0.8967, acc: 0.5516
loss: 0.8848, acc: 0.5597
loss: 0.8734, acc: 0.5671
loss: 0.8627, acc: 0.5748
loss: 0.8539, acc: 0.5819
loss: 0.8395, acc: 0.5905
loss: 0.8297, acc: 0.5973
loss: 0.8227, acc: 0.6020
loss: 0.8163, acc: 0.6068
loss: 0.8130, acc: 0.6097
loss: 0.8058, acc: 0.6147
loss: 0.7979, acc: 0.6200
loss: 0.7903, acc: 0.6255
loss: 0.7863, acc: 0.6275
loss: 0.7795, acc: 0.6316
loss: 0.7741, acc: 0.6349
loss: 0.7678, acc: 0.6391
loss: 0.7620, acc: 0.6422
loss: 0.7580, acc: 0.6458
loss: 0.7554, acc: 0.6478
loss: 0.7514, acc: 0.6501
loss: 0.7453, acc: 0.6544
loss: 0.7410, acc: 0.6575
loss: 0.7354, acc: 0.6604
loss: 0.7303, acc: 0.6633
loss: 0.7266, acc: 0.6658
loss: 0.7234, acc: 0.6674
loss: 0.7211, acc: 0.6691
loss: 0.7164, acc: 0.6726
loss: 0.7113, acc: 0.6757
loss: 0.7066, acc: 0.6785
loss: 0.7062, acc: 0.6789
loss: 0.7023, acc: 0.6808
loss: 0.6998, acc: 0.6828
loss: 0.6953, acc: 0.6855
loss: 0.6923, acc: 0.6872
loss: 0.6890, acc: 0.6889
loss: 0.6854, acc: 0.6912
loss: 0.6830, acc: 0.6925
loss: 0.6795, acc: 0.6949
loss: 0.6766, acc: 0.6967
loss: 0.6729, acc: 0.6987
loss: 0.6694, acc: 0.7003
loss: 0.6675, acc: 0.7017
loss: 0.6648, acc: 0.7031
loss: 0.6615, acc: 0.7049
loss: 0.6588, acc: 0.7062
> val_acc: 0.8093, val_f1: 0.8056
>> saved: /media/b115/Backup/NLP/roberta/mams/acc_0.8093_f1_0.8056_230828-0731.model
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.3372, acc: 0.8625
loss: 0.3850, acc: 0.8594
loss: 0.4129, acc: 0.8562
loss: 0.4065, acc: 0.8562
loss: 0.4042, acc: 0.8525
loss: 0.4053, acc: 0.8490
loss: 0.3970, acc: 0.8536
loss: 0.3990, acc: 0.8516
loss: 0.3989, acc: 0.8528
loss: 0.3993, acc: 0.8519
loss: 0.3993, acc: 0.8517
loss: 0.3989, acc: 0.8531
loss: 0.3960, acc: 0.8534
loss: 0.3931, acc: 0.8545
loss: 0.4002, acc: 0.8504
loss: 0.4009, acc: 0.8492
loss: 0.3976, acc: 0.8518
loss: 0.3952, acc: 0.8517
loss: 0.3925, acc: 0.8523
loss: 0.3912, acc: 0.8531
loss: 0.3906, acc: 0.8530
loss: 0.3903, acc: 0.8528
loss: 0.3943, acc: 0.8508
loss: 0.3939, acc: 0.8510
loss: 0.3921, acc: 0.8525
loss: 0.3942, acc: 0.8524
loss: 0.3935, acc: 0.8532
loss: 0.3936, acc: 0.8531
loss: 0.3943, acc: 0.8526
loss: 0.3925, acc: 0.8535
loss: 0.3928, acc: 0.8534
loss: 0.3913, acc: 0.8539
loss: 0.3926, acc: 0.8528
loss: 0.3915, acc: 0.8535
loss: 0.3914, acc: 0.8539
loss: 0.3908, acc: 0.8543
loss: 0.3897, acc: 0.8549
loss: 0.3891, acc: 0.8546
loss: 0.3905, acc: 0.8545
loss: 0.3884, acc: 0.8550
loss: 0.3886, acc: 0.8544
loss: 0.3899, acc: 0.8542
loss: 0.3903, acc: 0.8536
loss: 0.3913, acc: 0.8531
loss: 0.3910, acc: 0.8535
loss: 0.3912, acc: 0.8535
loss: 0.3896, acc: 0.8541
loss: 0.3919, acc: 0.8534
loss: 0.3912, acc: 0.8536
loss: 0.3909, acc: 0.8539
loss: 0.3908, acc: 0.8538
loss: 0.3903, acc: 0.8537
loss: 0.3884, acc: 0.8547
loss: 0.3879, acc: 0.8547
loss: 0.3875, acc: 0.8545
loss: 0.3869, acc: 0.8548
loss: 0.3882, acc: 0.8542
loss: 0.3879, acc: 0.8546
loss: 0.3877, acc: 0.8548
loss: 0.3868, acc: 0.8549
loss: 0.3865, acc: 0.8552
loss: 0.3851, acc: 0.8559
loss: 0.3843, acc: 0.8558
loss: 0.3834, acc: 0.8560
loss: 0.3831, acc: 0.8562
loss: 0.3830, acc: 0.8562
loss: 0.3818, acc: 0.8568
loss: 0.3826, acc: 0.8564
loss: 0.3837, acc: 0.8559
loss: 0.3851, acc: 0.8552
> val_acc: 0.8228, val_f1: 0.8189
>> saved: /media/b115/Backup/NLP/roberta/mams/acc_0.8228_f1_0.8189_230828-0733.model
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.2797, acc: 0.9250
loss: 0.2716, acc: 0.9125
loss: 0.2439, acc: 0.9271
loss: 0.2586, acc: 0.9187
loss: 0.2798, acc: 0.9137
loss: 0.3130, acc: 0.9000
loss: 0.3088, acc: 0.9009
loss: 0.3046, acc: 0.9008
loss: 0.2950, acc: 0.9021
loss: 0.2911, acc: 0.9006
loss: 0.2834, acc: 0.9040
loss: 0.2833, acc: 0.9042
loss: 0.2809, acc: 0.9024
loss: 0.2770, acc: 0.9027
loss: 0.2763, acc: 0.9042
loss: 0.2764, acc: 0.9043
loss: 0.2722, acc: 0.9059
loss: 0.2685, acc: 0.9069
loss: 0.2679, acc: 0.9066
loss: 0.2711, acc: 0.9034
loss: 0.2739, acc: 0.9024
loss: 0.2761, acc: 0.9017
loss: 0.2728, acc: 0.9030
loss: 0.2735, acc: 0.9021
loss: 0.2703, acc: 0.9035
loss: 0.2727, acc: 0.9024
loss: 0.2728, acc: 0.9019
loss: 0.2718, acc: 0.9025
loss: 0.2740, acc: 0.9015
loss: 0.2737, acc: 0.9019
loss: 0.2750, acc: 0.9014
loss: 0.2731, acc: 0.9023
loss: 0.2741, acc: 0.9021
loss: 0.2758, acc: 0.9017
loss: 0.2770, acc: 0.9002
loss: 0.2761, acc: 0.9002
loss: 0.2734, acc: 0.9007
loss: 0.2742, acc: 0.9008
loss: 0.2747, acc: 0.9005
loss: 0.2726, acc: 0.9011
loss: 0.2729, acc: 0.9008
loss: 0.2758, acc: 0.8994
loss: 0.2758, acc: 0.8990
loss: 0.2742, acc: 0.8993
loss: 0.2740, acc: 0.8999
loss: 0.2734, acc: 0.9008
loss: 0.2744, acc: 0.9007
loss: 0.2785, acc: 0.8999
loss: 0.2789, acc: 0.8996
loss: 0.2808, acc: 0.8989
loss: 0.2812, acc: 0.8984
loss: 0.2799, acc: 0.8984
loss: 0.2810, acc: 0.8980
loss: 0.2823, acc: 0.8976
loss: 0.2824, acc: 0.8975
loss: 0.2844, acc: 0.8967
loss: 0.2854, acc: 0.8961
loss: 0.2866, acc: 0.8957
loss: 0.2856, acc: 0.8960
loss: 0.2849, acc: 0.8962
loss: 0.2836, acc: 0.8965
loss: 0.2825, acc: 0.8970
loss: 0.2831, acc: 0.8966
loss: 0.2840, acc: 0.8961
loss: 0.2841, acc: 0.8957
loss: 0.2856, acc: 0.8953
loss: 0.2871, acc: 0.8944
loss: 0.2887, acc: 0.8938
loss: 0.2897, acc: 0.8930
loss: 0.2910, acc: 0.8925
> val_acc: 0.8131, val_f1: 0.8103
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 0.2309, acc: 0.9125
loss: 0.2107, acc: 0.9187
loss: 0.1907, acc: 0.9292
loss: 0.1818, acc: 0.9344
loss: 0.1619, acc: 0.9437
loss: 0.1578, acc: 0.9427
loss: 0.1617, acc: 0.9420
loss: 0.1713, acc: 0.9398
loss: 0.1767, acc: 0.9375
loss: 0.1810, acc: 0.9363
loss: 0.1826, acc: 0.9347
loss: 0.1826, acc: 0.9349
loss: 0.1813, acc: 0.9356
loss: 0.1799, acc: 0.9348
loss: 0.1828, acc: 0.9342
loss: 0.1809, acc: 0.9344
loss: 0.1823, acc: 0.9357
loss: 0.1809, acc: 0.9361
loss: 0.1808, acc: 0.9365
loss: 0.1792, acc: 0.9375
loss: 0.1809, acc: 0.9354
loss: 0.1818, acc: 0.9344
loss: 0.1778, acc: 0.9359
loss: 0.1769, acc: 0.9367
loss: 0.1768, acc: 0.9373
loss: 0.1775, acc: 0.9368
loss: 0.1792, acc: 0.9363
loss: 0.1796, acc: 0.9362
loss: 0.1793, acc: 0.9360
loss: 0.1828, acc: 0.9346
loss: 0.1828, acc: 0.9351
loss: 0.1839, acc: 0.9355
loss: 0.1836, acc: 0.9356
loss: 0.1844, acc: 0.9347
loss: 0.1859, acc: 0.9345
loss: 0.1887, acc: 0.9339
loss: 0.1894, acc: 0.9334
loss: 0.1890, acc: 0.9336
loss: 0.1910, acc: 0.9330
loss: 0.1929, acc: 0.9322
loss: 0.1922, acc: 0.9325
loss: 0.1925, acc: 0.9323
loss: 0.1933, acc: 0.9320
loss: 0.1929, acc: 0.9321
loss: 0.1932, acc: 0.9318
loss: 0.1938, acc: 0.9315
loss: 0.1935, acc: 0.9315
loss: 0.1943, acc: 0.9306
loss: 0.1936, acc: 0.9307
loss: 0.1932, acc: 0.9307
loss: 0.1938, acc: 0.9304
loss: 0.1934, acc: 0.9306
loss: 0.1947, acc: 0.9303
loss: 0.1949, acc: 0.9302
loss: 0.1964, acc: 0.9297
loss: 0.1967, acc: 0.9299
loss: 0.1983, acc: 0.9291
loss: 0.1984, acc: 0.9288
loss: 0.1986, acc: 0.9288
loss: 0.1985, acc: 0.9286
loss: 0.1993, acc: 0.9286
loss: 0.1993, acc: 0.9285
loss: 0.1992, acc: 0.9286
loss: 0.2002, acc: 0.9282
loss: 0.2006, acc: 0.9279
loss: 0.2004, acc: 0.9281
loss: 0.1998, acc: 0.9283
loss: 0.2005, acc: 0.9280
loss: 0.2010, acc: 0.9280
loss: 0.2019, acc: 0.9276
> val_acc: 0.8273, val_f1: 0.8241
>> saved: /media/b115/Backup/NLP/roberta/mams/acc_0.8273_f1_0.8241_230828-0737.model
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
loss: 0.2424, acc: 0.9375
loss: 0.1892, acc: 0.9500
loss: 0.1915, acc: 0.9479
loss: 0.1787, acc: 0.9453
loss: 0.1695, acc: 0.9450
loss: 0.1632, acc: 0.9479
loss: 0.1518, acc: 0.9518
loss: 0.1450, acc: 0.9531
loss: 0.1440, acc: 0.9528
loss: 0.1436, acc: 0.9500
loss: 0.1442, acc: 0.9500
loss: 0.1496, acc: 0.9469
loss: 0.1478, acc: 0.9476
loss: 0.1476, acc: 0.9473
loss: 0.1501, acc: 0.9467
loss: 0.1513, acc: 0.9461
loss: 0.1503, acc: 0.9471
loss: 0.1475, acc: 0.9476
loss: 0.1466, acc: 0.9480
loss: 0.1425, acc: 0.9494
loss: 0.1419, acc: 0.9500
loss: 0.1429, acc: 0.9497
loss: 0.1422, acc: 0.9500
loss: 0.1398, acc: 0.9505
loss: 0.1397, acc: 0.9507
loss: 0.1386, acc: 0.9517
loss: 0.1400, acc: 0.9514
loss: 0.1395, acc: 0.9516
loss: 0.1383, acc: 0.9519
loss: 0.1375, acc: 0.9525
loss: 0.1360, acc: 0.9528
loss: 0.1386, acc: 0.9523
loss: 0.1403, acc: 0.9513
loss: 0.1395, acc: 0.9518
loss: 0.1413, acc: 0.9513
loss: 0.1419, acc: 0.9512
loss: 0.1433, acc: 0.9512
loss: 0.1438, acc: 0.9515
loss: 0.1441, acc: 0.9508
loss: 0.1458, acc: 0.9502
loss: 0.1460, acc: 0.9498
loss: 0.1458, acc: 0.9493
loss: 0.1457, acc: 0.9494
loss: 0.1455, acc: 0.9491
loss: 0.1442, acc: 0.9497
loss: 0.1446, acc: 0.9493
loss: 0.1464, acc: 0.9485
loss: 0.1452, acc: 0.9490
loss: 0.1454, acc: 0.9487
loss: 0.1446, acc: 0.9487
loss: 0.1430, acc: 0.9494
loss: 0.1450, acc: 0.9494
loss: 0.1444, acc: 0.9492
loss: 0.1449, acc: 0.9492
loss: 0.1451, acc: 0.9490
loss: 0.1462, acc: 0.9490
loss: 0.1465, acc: 0.9487
loss: 0.1465, acc: 0.9487
loss: 0.1460, acc: 0.9489
loss: 0.1465, acc: 0.9487
loss: 0.1464, acc: 0.9488
loss: 0.1458, acc: 0.9489
loss: 0.1459, acc: 0.9489
loss: 0.1458, acc: 0.9489
loss: 0.1455, acc: 0.9488
loss: 0.1449, acc: 0.9489
loss: 0.1447, acc: 0.9488
loss: 0.1461, acc: 0.9481
loss: 0.1463, acc: 0.9480
loss: 0.1456, acc: 0.9480
> val_acc: 0.8416, val_f1: 0.8372
>> saved: /media/b115/Backup/NLP/roberta/mams/acc_0.8416_f1_0.8372_230828-0739.model
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 5
loss: 0.1530, acc: 0.9563
loss: 0.1188, acc: 0.9563
loss: 0.1248, acc: 0.9500
loss: 0.1246, acc: 0.9547
loss: 0.1186, acc: 0.9563
loss: 0.1133, acc: 0.9573
loss: 0.1079, acc: 0.9589
loss: 0.1043, acc: 0.9609
loss: 0.1059, acc: 0.9618
loss: 0.1095, acc: 0.9613
loss: 0.1039, acc: 0.9631
loss: 0.1039, acc: 0.9635
loss: 0.0994, acc: 0.9659
loss: 0.0989, acc: 0.9661
loss: 0.0985, acc: 0.9667
loss: 0.0980, acc: 0.9660
loss: 0.0988, acc: 0.9654
loss: 0.1004, acc: 0.9649
loss: 0.1010, acc: 0.9641
loss: 0.0992, acc: 0.9647
loss: 0.0997, acc: 0.9643
loss: 0.0991, acc: 0.9645
loss: 0.0996, acc: 0.9641
loss: 0.1001, acc: 0.9638
loss: 0.1013, acc: 0.9635
loss: 0.0991, acc: 0.9642
loss: 0.0994, acc: 0.9639
loss: 0.0997, acc: 0.9632
loss: 0.1016, acc: 0.9623
loss: 0.1006, acc: 0.9627
loss: 0.1003, acc: 0.9623
loss: 0.1023, acc: 0.9615
loss: 0.1017, acc: 0.9619
loss: 0.1024, acc: 0.9619
loss: 0.1016, acc: 0.9623
loss: 0.1034, acc: 0.9613
loss: 0.1034, acc: 0.9615
loss: 0.1037, acc: 0.9612
loss: 0.1036, acc: 0.9612
loss: 0.1029, acc: 0.9619
loss: 0.1029, acc: 0.9620
loss: 0.1030, acc: 0.9619
loss: 0.1027, acc: 0.9621
loss: 0.1033, acc: 0.9621
loss: 0.1026, acc: 0.9624
loss: 0.1028, acc: 0.9624
loss: 0.1017, acc: 0.9628
loss: 0.1014, acc: 0.9628
loss: 0.1015, acc: 0.9629
loss: 0.1014, acc: 0.9630
loss: 0.1005, acc: 0.9632
loss: 0.1002, acc: 0.9635
loss: 0.1007, acc: 0.9632
loss: 0.1012, acc: 0.9628
loss: 0.1016, acc: 0.9628
loss: 0.1029, acc: 0.9628
loss: 0.1029, acc: 0.9625
loss: 0.1029, acc: 0.9627
loss: 0.1029, acc: 0.9627
loss: 0.1021, acc: 0.9627
loss: 0.1012, acc: 0.9632
loss: 0.1013, acc: 0.9633
loss: 0.1014, acc: 0.9634
loss: 0.1029, acc: 0.9629
loss: 0.1042, acc: 0.9626
loss: 0.1049, acc: 0.9624
loss: 0.1050, acc: 0.9626
loss: 0.1053, acc: 0.9625
loss: 0.1052, acc: 0.9627
loss: 0.1054, acc: 0.9624
> val_acc: 0.8453, val_f1: 0.8396
>> saved: /media/b115/Backup/NLP/roberta/mams/acc_0.8453_f1_0.8396_230828-0741.model
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 6
loss: 0.0501, acc: 0.9875
loss: 0.0458, acc: 0.9906
loss: 0.0492, acc: 0.9833
loss: 0.0552, acc: 0.9781
loss: 0.0751, acc: 0.9700
loss: 0.0751, acc: 0.9719
loss: 0.0752, acc: 0.9732
loss: 0.0708, acc: 0.9750
loss: 0.0734, acc: 0.9729
loss: 0.0694, acc: 0.9756
loss: 0.0684, acc: 0.9761
loss: 0.0660, acc: 0.9771
loss: 0.0703, acc: 0.9745
loss: 0.0701, acc: 0.9746
loss: 0.0732, acc: 0.9738
loss: 0.0742, acc: 0.9734
loss: 0.0778, acc: 0.9724
loss: 0.0810, acc: 0.9715
loss: 0.0838, acc: 0.9694
loss: 0.0852, acc: 0.9684
loss: 0.0849, acc: 0.9688
loss: 0.0832, acc: 0.9693
loss: 0.0815, acc: 0.9704
loss: 0.0812, acc: 0.9711
loss: 0.0797, acc: 0.9718
loss: 0.0774, acc: 0.9726
loss: 0.0754, acc: 0.9731
loss: 0.0754, acc: 0.9737
loss: 0.0761, acc: 0.9737
loss: 0.0767, acc: 0.9735
loss: 0.0758, acc: 0.9740
loss: 0.0749, acc: 0.9744
loss: 0.0743, acc: 0.9748
loss: 0.0750, acc: 0.9748
loss: 0.0746, acc: 0.9746
loss: 0.0759, acc: 0.9745
loss: 0.0751, acc: 0.9747
loss: 0.0756, acc: 0.9747
loss: 0.0765, acc: 0.9745
loss: 0.0774, acc: 0.9742
loss: 0.0788, acc: 0.9741
loss: 0.0784, acc: 0.9741
loss: 0.0788, acc: 0.9740
loss: 0.0796, acc: 0.9736
loss: 0.0801, acc: 0.9736
loss: 0.0795, acc: 0.9738
loss: 0.0784, acc: 0.9743
loss: 0.0780, acc: 0.9745
loss: 0.0780, acc: 0.9745
loss: 0.0787, acc: 0.9742
loss: 0.0811, acc: 0.9740
loss: 0.0815, acc: 0.9738
loss: 0.0814, acc: 0.9739
loss: 0.0814, acc: 0.9738
loss: 0.0816, acc: 0.9735
loss: 0.0826, acc: 0.9732
loss: 0.0829, acc: 0.9730
loss: 0.0827, acc: 0.9730
loss: 0.0829, acc: 0.9730
loss: 0.0828, acc: 0.9729
loss: 0.0829, acc: 0.9728
loss: 0.0832, acc: 0.9728
loss: 0.0833, acc: 0.9726
loss: 0.0830, acc: 0.9728
loss: 0.0828, acc: 0.9730
loss: 0.0824, acc: 0.9730
loss: 0.0828, acc: 0.9729
loss: 0.0824, acc: 0.9730
loss: 0.0815, acc: 0.9734
loss: 0.0814, acc: 0.9733
> val_acc: 0.8348, val_f1: 0.8305
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 7
loss: 0.0500, acc: 0.9750
loss: 0.0574, acc: 0.9781
loss: 0.0743, acc: 0.9750
loss: 0.0622, acc: 0.9797
loss: 0.0737, acc: 0.9775
loss: 0.0739, acc: 0.9771
loss: 0.0685, acc: 0.9786
loss: 0.0700, acc: 0.9781
loss: 0.0714, acc: 0.9778
loss: 0.0674, acc: 0.9788
loss: 0.0659, acc: 0.9790
loss: 0.0654, acc: 0.9797
loss: 0.0699, acc: 0.9793
loss: 0.0668, acc: 0.9804
loss: 0.0678, acc: 0.9792
loss: 0.0710, acc: 0.9781
loss: 0.0697, acc: 0.9779
loss: 0.0681, acc: 0.9785
loss: 0.0663, acc: 0.9789
loss: 0.0645, acc: 0.9794
loss: 0.0656, acc: 0.9789
loss: 0.0677, acc: 0.9784
loss: 0.0674, acc: 0.9783
loss: 0.0694, acc: 0.9771
loss: 0.0688, acc: 0.9772
loss: 0.0688, acc: 0.9774
loss: 0.0724, acc: 0.9769
loss: 0.0730, acc: 0.9766
loss: 0.0727, acc: 0.9769
loss: 0.0729, acc: 0.9765
loss: 0.0726, acc: 0.9764
loss: 0.0722, acc: 0.9764
loss: 0.0718, acc: 0.9765
loss: 0.0721, acc: 0.9757
loss: 0.0727, acc: 0.9754
loss: 0.0719, acc: 0.9753
loss: 0.0715, acc: 0.9755
loss: 0.0724, acc: 0.9755
loss: 0.0720, acc: 0.9758
loss: 0.0709, acc: 0.9762
loss: 0.0708, acc: 0.9762
loss: 0.0707, acc: 0.9763
loss: 0.0706, acc: 0.9763
loss: 0.0702, acc: 0.9764
loss: 0.0703, acc: 0.9764
loss: 0.0697, acc: 0.9768
loss: 0.0695, acc: 0.9770
loss: 0.0687, acc: 0.9772
loss: 0.0687, acc: 0.9772
loss: 0.0684, acc: 0.9774
loss: 0.0681, acc: 0.9775
loss: 0.0677, acc: 0.9775
loss: 0.0678, acc: 0.9776
loss: 0.0678, acc: 0.9778
loss: 0.0671, acc: 0.9780
loss: 0.0674, acc: 0.9779
loss: 0.0667, acc: 0.9781
loss: 0.0673, acc: 0.9779
loss: 0.0671, acc: 0.9781
loss: 0.0675, acc: 0.9776
loss: 0.0676, acc: 0.9777
loss: 0.0677, acc: 0.9777
loss: 0.0678, acc: 0.9777
loss: 0.0679, acc: 0.9776
loss: 0.0685, acc: 0.9776
loss: 0.0680, acc: 0.9777
loss: 0.0691, acc: 0.9776
loss: 0.0686, acc: 0.9778
loss: 0.0681, acc: 0.9780
loss: 0.0678, acc: 0.9781
> val_acc: 0.8423, val_f1: 0.8361
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 8
loss: 0.0951, acc: 0.9688
loss: 0.0674, acc: 0.9781
loss: 0.0604, acc: 0.9771
loss: 0.0681, acc: 0.9766
loss: 0.0621, acc: 0.9788
loss: 0.0646, acc: 0.9760
loss: 0.0722, acc: 0.9759
loss: 0.0716, acc: 0.9758
loss: 0.0688, acc: 0.9764
loss: 0.0640, acc: 0.9781
loss: 0.0653, acc: 0.9778
loss: 0.0619, acc: 0.9792
loss: 0.0593, acc: 0.9798
loss: 0.0594, acc: 0.9790
loss: 0.0589, acc: 0.9796
loss: 0.0592, acc: 0.9801
loss: 0.0565, acc: 0.9812
loss: 0.0555, acc: 0.9812
loss: 0.0605, acc: 0.9803
loss: 0.0637, acc: 0.9800
loss: 0.0622, acc: 0.9801
loss: 0.0649, acc: 0.9795
loss: 0.0651, acc: 0.9793
loss: 0.0658, acc: 0.9789
loss: 0.0659, acc: 0.9790
loss: 0.0656, acc: 0.9793
loss: 0.0655, acc: 0.9792
loss: 0.0645, acc: 0.9797
loss: 0.0660, acc: 0.9791
loss: 0.0660, acc: 0.9794
loss: 0.0668, acc: 0.9794
loss: 0.0669, acc: 0.9793
loss: 0.0651, acc: 0.9799
loss: 0.0638, acc: 0.9803
loss: 0.0633, acc: 0.9805
loss: 0.0623, acc: 0.9809
loss: 0.0616, acc: 0.9811
loss: 0.0603, acc: 0.9816
loss: 0.0602, acc: 0.9814
loss: 0.0598, acc: 0.9811
loss: 0.0599, acc: 0.9811
loss: 0.0606, acc: 0.9811
loss: 0.0628, acc: 0.9801
loss: 0.0640, acc: 0.9798
loss: 0.0632, acc: 0.9800
loss: 0.0630, acc: 0.9799
loss: 0.0625, acc: 0.9801
loss: 0.0622, acc: 0.9801
loss: 0.0635, acc: 0.9795
loss: 0.0647, acc: 0.9792
loss: 0.0645, acc: 0.9793
loss: 0.0643, acc: 0.9793
loss: 0.0637, acc: 0.9795
loss: 0.0633, acc: 0.9795
loss: 0.0643, acc: 0.9794
loss: 0.0647, acc: 0.9792
loss: 0.0644, acc: 0.9794
loss: 0.0660, acc: 0.9787
loss: 0.0653, acc: 0.9789
loss: 0.0659, acc: 0.9785
loss: 0.0662, acc: 0.9785
loss: 0.0663, acc: 0.9784
loss: 0.0668, acc: 0.9781
loss: 0.0663, acc: 0.9783
loss: 0.0676, acc: 0.9781
loss: 0.0674, acc: 0.9782
loss: 0.0677, acc: 0.9780
loss: 0.0676, acc: 0.9780
loss: 0.0673, acc: 0.9781
loss: 0.0669, acc: 0.9782
> val_acc: 0.8131, val_f1: 0.8107
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 9
loss: 0.0378, acc: 0.9812
loss: 0.0413, acc: 0.9844
loss: 0.0538, acc: 0.9792
loss: 0.0506, acc: 0.9812
loss: 0.0612, acc: 0.9775
loss: 0.0678, acc: 0.9781
loss: 0.0668, acc: 0.9795
loss: 0.0620, acc: 0.9820
loss: 0.0590, acc: 0.9819
loss: 0.0550, acc: 0.9831
loss: 0.0527, acc: 0.9841
loss: 0.0509, acc: 0.9844
loss: 0.0521, acc: 0.9846
loss: 0.0535, acc: 0.9839
loss: 0.0511, acc: 0.9846
loss: 0.0493, acc: 0.9848
loss: 0.0509, acc: 0.9835
loss: 0.0506, acc: 0.9837
loss: 0.0516, acc: 0.9832
loss: 0.0494, acc: 0.9841
loss: 0.0504, acc: 0.9836
loss: 0.0506, acc: 0.9838
loss: 0.0523, acc: 0.9837
loss: 0.0509, acc: 0.9844
loss: 0.0512, acc: 0.9840
loss: 0.0504, acc: 0.9841
loss: 0.0509, acc: 0.9843
loss: 0.0514, acc: 0.9839
loss: 0.0517, acc: 0.9843
loss: 0.0526, acc: 0.9840
loss: 0.0517, acc: 0.9845
loss: 0.0518, acc: 0.9844
loss: 0.0514, acc: 0.9841
loss: 0.0505, acc: 0.9846
loss: 0.0499, acc: 0.9848
loss: 0.0494, acc: 0.9851
loss: 0.0497, acc: 0.9851
loss: 0.0509, acc: 0.9849
loss: 0.0515, acc: 0.9848
loss: 0.0529, acc: 0.9845
loss: 0.0554, acc: 0.9837
loss: 0.0555, acc: 0.9835
loss: 0.0551, acc: 0.9834
loss: 0.0549, acc: 0.9835
loss: 0.0551, acc: 0.9836
loss: 0.0549, acc: 0.9836
loss: 0.0572, acc: 0.9830
loss: 0.0574, acc: 0.9829
loss: 0.0572, acc: 0.9829
loss: 0.0571, acc: 0.9828
loss: 0.0578, acc: 0.9825
loss: 0.0582, acc: 0.9825
loss: 0.0579, acc: 0.9825
loss: 0.0576, acc: 0.9826
loss: 0.0581, acc: 0.9822
loss: 0.0577, acc: 0.9823
loss: 0.0581, acc: 0.9821
loss: 0.0606, acc: 0.9815
loss: 0.0605, acc: 0.9814
loss: 0.0608, acc: 0.9812
loss: 0.0616, acc: 0.9811
loss: 0.0613, acc: 0.9811
loss: 0.0612, acc: 0.9811
loss: 0.0612, acc: 0.9808
loss: 0.0610, acc: 0.9807
loss: 0.0610, acc: 0.9807
loss: 0.0607, acc: 0.9808
loss: 0.0603, acc: 0.9809
loss: 0.0604, acc: 0.9809
loss: 0.0606, acc: 0.9808
> val_acc: 0.8348, val_f1: 0.8290
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 10
loss: 0.0777, acc: 0.9812
loss: 0.0557, acc: 0.9844
loss: 0.0423, acc: 0.9896
loss: 0.0415, acc: 0.9875
loss: 0.0391, acc: 0.9875
loss: 0.0350, acc: 0.9885
loss: 0.0322, acc: 0.9902
loss: 0.0334, acc: 0.9906
loss: 0.0365, acc: 0.9910
loss: 0.0339, acc: 0.9912
loss: 0.0361, acc: 0.9903
loss: 0.0421, acc: 0.9891
loss: 0.0426, acc: 0.9880
loss: 0.0416, acc: 0.9879
loss: 0.0421, acc: 0.9871
loss: 0.0455, acc: 0.9871
loss: 0.0434, acc: 0.9879
loss: 0.0448, acc: 0.9875
loss: 0.0436, acc: 0.9878
loss: 0.0475, acc: 0.9869
loss: 0.0467, acc: 0.9869
loss: 0.0479, acc: 0.9866
loss: 0.0478, acc: 0.9864
loss: 0.0463, acc: 0.9867
loss: 0.0476, acc: 0.9865
loss: 0.0475, acc: 0.9865
loss: 0.0466, acc: 0.9868
loss: 0.0470, acc: 0.9864
loss: 0.0460, acc: 0.9866
loss: 0.0449, acc: 0.9871
loss: 0.0438, acc: 0.9873
loss: 0.0442, acc: 0.9873
loss: 0.0434, acc: 0.9873
loss: 0.0426, acc: 0.9875
loss: 0.0416, acc: 0.9879
loss: 0.0406, acc: 0.9882
loss: 0.0412, acc: 0.9880
loss: 0.0410, acc: 0.9882
loss: 0.0401, acc: 0.9885
loss: 0.0402, acc: 0.9881
loss: 0.0410, acc: 0.9880
loss: 0.0412, acc: 0.9878
loss: 0.0417, acc: 0.9874
loss: 0.0416, acc: 0.9875
loss: 0.0412, acc: 0.9875
loss: 0.0410, acc: 0.9875
loss: 0.0407, acc: 0.9876
loss: 0.0404, acc: 0.9878
loss: 0.0400, acc: 0.9879
loss: 0.0394, acc: 0.9881
loss: 0.0389, acc: 0.9884
loss: 0.0391, acc: 0.9881
loss: 0.0388, acc: 0.9881
loss: 0.0390, acc: 0.9880
loss: 0.0391, acc: 0.9880
loss: 0.0394, acc: 0.9878
loss: 0.0408, acc: 0.9876
loss: 0.0411, acc: 0.9875
loss: 0.0411, acc: 0.9874
loss: 0.0418, acc: 0.9870
loss: 0.0424, acc: 0.9869
loss: 0.0425, acc: 0.9868
loss: 0.0423, acc: 0.9867
loss: 0.0431, acc: 0.9864
loss: 0.0431, acc: 0.9864
loss: 0.0431, acc: 0.9864
loss: 0.0429, acc: 0.9864
loss: 0.0428, acc: 0.9865
loss: 0.0426, acc: 0.9866
loss: 0.0425, acc: 0.9867
> val_acc: 0.8326, val_f1: 0.8281
>> test_acc: 0.8406, test_f1: 0.8344
>> test_acc: 0.8331, test_f1: 0.8264
>> test_acc: 0.8211, test_f1: 0.8130
>> test_acc: 0.8406, test_f1: 0.8344

>> avg_test_acc: 0.8316, avg_test_f1: 0.8246
>> max_test_acc: 0.8406, max_test_f1: 0.8344
